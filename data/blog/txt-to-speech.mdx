---
title: '离线语音合成'
date: '2025-06-09 14:56:25'
tags: ['android', '语音', '调研']
draft: false
summary: '语音合成是一种将文本转换为自然语音的技术。其核心目标是让计算机像人类一样 “说话”，使机器能够以语音形式传递信息，提升人机交互的自然性和便捷性。'
authors: ['default']
---

## 简介

语音合成（Text-to-Speech，TTS） 是一种将文本转换为自然语音的技术。其核心目标是让计算机像人类一样 “说话”，使机器能够以语音形式传递信息，提升人机交互的自然性和便捷性。

## 原理与技术实现

语音合成的实现通常需要结合语言学、声学、信号处理等多领域知识，主要流程包括：

1. 文本分析
   对输入文本进行语法分析、语义理解，确定断句、重音、情感基调等（例如区分问句、陈述句的语调）。
   处理特殊符号（如数字、缩写、标点），转换为对应的发音（如 “2023” 转为 “二千零二十三” 或 “two thousand twenty-three”）。
2. 声学参数生成
   根据文本分析结果，生成对应的语音参数（如基频、共振峰、时长等），这些参数决定了语音的音高、音色和节奏。
   早期技术依赖人工标注的语音数据库（如拼接合成），现代则通过深度学习模型（如神经网络）自动学习文本与语音的映射关系。
3. 语音合成
   利用声学参数和合成器（如声码器）生成波形音频，常见方法包括：
   拼接合成：从预先录制的语音片段中拼接出完整语音（音质自然但灵活性低）。
   参数合成：通过数学模型生成语音参数并合成波形（灵活性高但早期音质生硬）。
   深度学习合成：基于神经网络（如 Tacotron、WaveNet、GPT-4 Voice 等）直接生成接近真人发音的语音，支持情感、语速调节。

## 语音合成方案

| 方案          | 说明                                                                                                                          | 备注                                                       | 官网                                                                                                                                                             |
| ------------- | ----------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Sherpa-onnx   | 依赖 ONNX Runtime 框架，提供从语音到文本（ASR）、文本到语音（TTS）和语音活动检测（VAD）等功能，适用于各种嵌入式系统和移动设备 |                                                            |                                                                                                                                                                  |
| PP-TTS        | 基于百度飞桨的语音方向的开源模型库，用于语音和音频中的各种关键任务的开发。提供面向端侧场景的轻量化推理引擎Paddle Lite。       | Android Demo不包含文本前端模块（将文本转换为音素序号数组） | [部署信息汇总](https://github.com/PaddlePaddle/PaddleSpeech/issues/3037)[TTSAndroid](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/TTSAndroid) |
| espeak-ng     | 使用“共振峰合成”方法，以较小的规模提供多种语言。语音清晰，可以高速使用                                                        | 不如基于人类语音记录的大型合成器自然或流畅，“机器音”       | [espeak-ng](https://github.com/espeak-ng/espeak-ng)                                                                                                              |
| TensorFlowTTS | 适用于 Tensorflow 2 的实时最先进的语音合成                                                                                    | 最新更新三年前                                             |                                                                                                                                                                  |
| Coqui TTS     | 用于文本转语音的深度学习工具包                                                                                                | 官方不支持Android运行                                      |                                                                                                                                                                  |
| CosyVoice2    | 阿里巴巴通义实验室语音团队推出的多语言语音合成模型                                                                            | 不支持端侧部署                                             |                                                                                                                                                                  |
| marytts       |                                                                                                                               | 服务器客户端模式，不提供离线TTS方案                        | [官网](https://github.com/marytts/marytts)                                                                                                                       |
| flite         | 开源的小型快速运行时文本到语音引擎                                                                                            | 不再维护                                                   | [官网](https://github.com/festvox/flite) [Android](https://github.com/happyalu/Flite-TTS-Engine-for-Android)                                                     |

## VITS 模型参数说明

`sherpa-onnx` 是一个用于端到端语音识别和语音合成的工具包，在运行 VITS 模型时，你提到的这些参数具有不同的含义：

### 模型与字典相关参数

- `model`：这是指向 VITS 模型文件的路径。模型文件中存储了经过训练的神经网络的权重和结构信息，`sherpa-onnx` 会依据这些信息来生成语音。例如，它可能是一个 `.onnx` 格式的文件，此文件是模型训练完成后被导出的。
- `lexicon`：这是指向词典文件的路径。词典文件记录了单词和其发音之间的对应关系。在语音合成时，系统需要借助这个词典把输入的文本转换为发音序列，进而生成语音。
- `tokens`：它指向的是包含模型所使用的所有可能的标记（tokens）的文件路径。标记是模型在处理文本时的基本单元，像单个字符、音节或者单词等都可能是标记。
- `dataDir`：该参数代表包含语音合成所需的其他数据文件的目录路径。这些数据文件也许包含音频样本、发音规则等，它们能够辅助模型生成更自然、准确的语音。
- `dictDir`：它表示存储词典和其他相关字典文件的目录路径。和 `lexicon` 有所不同，`dictDir` 更侧重于整个字典文件所在的目录，而 `lexicon` 则是具体的词典文件。

### 语音生成控制参数

- `noiseScale`：这个参数用于控制生成语音时的噪声强度。噪声在语音合成里能够增加语音的自然度和多样性。`noiseScale` 的值越大，生成的语音就越多样化，但也可能会使语音质量有所下降；值越小，语音就越稳定，但可能会缺乏自然的变化。
- `noiseScaleW`：此参数用于控制音高（pitch）的噪声强度。音高是语音的一个重要特征，它会影响语音的情感和语气。`noiseScaleW` 可以对音高的变化进行调整，从而使生成的语音更富有情感和表现力。
- `lengthScale`：该参数用于控制生成语音的长度。`lengthScale` 的值大于 1 时，生成的语音会变长，语速变慢；值小于 1 时，语音会变短，语速变快。通过调整这个参数，能够根据具体需求对语音的时长和语速进行控制。

通过合理调整这些参数，你可以让 `sherpa-onnx` 运行 VITS 模型时生成更符合需求的语音。

## Matcha 模型参数说明

### 模型相关参数

- `acousticModel`：指向声学模型文件的路径。声学模型是语音合成系统中的关键部分，它负责将输入的文本特征转换为语音的声学特征，例如音素、音高、音长等信息。Matcha 的声学模型经过训练，能够学习到文本和声学特征之间的映射关系，从而为后续生成语音提供基础。
- `vocoder`：指向声码器文件的路径。声码器的作用是将声学模型输出的声学特征转换为可听的语音波形。它会对声学特征进行进一步处理，生成具有自然音质的语音信号。不同的声码器在音质、合成速度等方面可能存在差异。
- `lexicon`：和运行 VITS 模型时的 `lexicon` 类似，它是指向词典文件的路径。词典文件记录了单词和其发音之间的对应关系，在语音合成过程中，系统需要依据这个词典把输入的文本转换为发音序列，进而传递给声学模型进行处理。
- `tokens`：该参数指向包含模型所使用的所有可能的标记（tokens）的文件路径。标记是模型在处理文本时的基本单元，可能是单个字符、音节或者单词等。声学模型和相关组件会基于这些标记来对输入文本进行编码和处理。

### 数据目录参数

- `dataDir`：表示包含语音合成所需的其他数据文件的目录路径。这些数据文件可能包括音频样本、发音规则、训练配置等，它们可以辅助模型生成更自然、准确的语音。例如，某些发音规则数据可以帮助处理特殊单词的发音。
- `dictDir`：代表存储词典和其他相关字典文件的目录路径。与 `lexicon` 不同，`dictDir` 更侧重于整个字典文件所在的目录，而 `lexicon` 则是具体的词典文件。这个目录可能包含多个不同用途的字典文件，以满足不同场景下的语音合成需求。

### 语音生成控制参数

- `noiseScale`：用于控制生成语音时的噪声强度。在语音合成中，适量的噪声可以增加语音的自然度和多样性。`noiseScale` 的值越大，生成的语音就越多样化，但可能会导致语音质量下降；值越小，语音就越稳定，但可能会缺乏自然的变化。
- `lengthScale`：用于控制生成语音的长度。当 `lengthScale` 的值大于 1 时，生成的语音会变长，语速变慢；值小于 1 时，语音会变短，语速变快。通过调整这个参数，可以根据具体需求对语音的时长和语速进行控制。

合理设置这些参数可以使 `sherpa-onnx` 在运行 Matcha 模型时生成高质量、符合需求的语音。

## Kokoro 模型参数说明

### 模型与资源文件相关参数

- `model`：这是指向 Kokoro 模型文件的路径。该模型文件存储着经过训练的神经网络的权重和结构信息，`sherpa-onnx`借助这些信息来执行语音合成任务。通常它是以`.onnx`格式存在的文件，是模型训练完成后被导出的结果。
- `voices`：它指定了语音的音色选项。不同的语音音色能让合成出来的语音呈现出不同的风格和特点，例如男性、女性、儿童的声音，或者不同地域口音的声音等。通过设置该参数，你可以选择自己想要的语音音色。
- `tokens`：此参数指向包含模型所使用的所有可能的标记（tokens）的文件路径。标记是模型在处理文本时的基本单元，可能是单个字符、音节或者单词等。Kokoro 模型会基于这些标记来对输入文本进行编码和处理。
- `lexicon`：这是指向词典文件的路径。词典文件记录了单词和其发音之间的对应关系。在语音合成时，系统会依据这个词典把输入的文本转换为发音序列，然后将其传递给模型进行进一步处理。
- `dictDir`：表示存储词典和其他相关字典文件的目录路径。与`lexicon`不同，`dictDir`更侧重于整个字典文件所在的目录，而`lexicon`则是具体的词典文件。这个目录可能包含多个不同用途的字典文件，以满足不同场景下的语音合成需求。
- `dataDir`：该参数代表包含语音合成所需的其他数据文件的目录路径。这些数据文件可能包含音频样本、发音规则、训练配置等，它们可以辅助模型生成更自然、准确的语音。

### 语音生成控制参数

- `lengthScale`：用于控制生成语音的长度。当`lengthScale`的值大于 1 时，生成的语音会变长，语速变慢；值小于 1 时，语音会变短，语速变快。通过调整这个参数，可以根据具体需求对语音的时长和语速进行控制。

通过合理配置这些参数，你可以让`sherpa-onnx`运行 Kokoro 模型时生成符合你需求的语音。

## 运行TTS模型配置参数说明

### 模型与规则文件相关参数

- `model`：该参数指向 TTS 模型文件的路径。模型文件中保存了经过训练的神经网络的权重和架构信息，`sherpa-onnx` 会依据这些信息把输入的文本转化为语音。一般而言，它是一个 `.onnx` 格式的文件，是模型训练完成后导出的结果。
- `ruleFsts`：`ruleFsts` 通常指向有限状态转换器（Finite State Transducer，FST）规则文件的路径。FST 是一种用于处理和转换序列数据的强大工具，在 TTS 里，FST 规则可用于执行文本的规范化、发音规则应用等任务。例如，它能把数字、缩写等转换为对应的发音形式。
- `ruleFars`：`ruleFars` 指向有限状态自动机集合（Finite State Automaton Repository，FAR）规则文件的路径。FAR 是多个 FST 的集合，它可以包含多个不同的 FST 规则，这些规则可以在不同的阶段或者针对不同的文本类型发挥作用，从而提高文本处理的灵活性和效率。

### 文本处理参数

- `maxNumSentences`：此参数规定了一次处理的最大句子数量。在进行语音合成时，输入的文本可能包含多个句子。通过设置 `maxNumSentences`，可以控制每次处理的句子数量，避免因处理过长的文本而导致内存占用过高或者性能下降。例如，当输入文本包含很多句子时，`sherpa-onnx` 会按照这个参数的值将文本分割成合适的部分进行处理。

### 语音效果参数

- `silenceScale`：该参数用于控制语音中静音部分的时长。在语音合成过程中，句子之间、词语之间通常会有一定的静音间隔，`silenceScale` 可以调整这些静音间隔的长度。当 `silenceScale` 的值大于 1 时，静音间隔会变长；当值小于 1 时，静音间隔会变短。通过调整这个参数，可以使生成的语音节奏更加自然、符合需求。

## 什么是 Real-Time Factor (RTF)

在 TTS（Text-to-Speech） 领域，RTF 通常指的是 Real-Time Factor，即“实时因子”。这是一个衡量 TTS 系统性能的重要指标，用来评估模型在语音生成过程中的效率。

### RTF计算公式

RTF 表示生成语音所需的处理时间与语音时长的比值。其公式为：

![RTF公式](/static/images/tts/rtf.png)

### 解释 RTF 值

RTF < 1：实时或更快的生成。生成语音所需时间少于语音时长。比如 RTF = 0.5 意味着生成一分钟语音只需要 30 秒。

RTF > 1：非实时。生成语音所需时间长于语音时长。比如 RTF = 2 意味着生成一分钟语音需要 2 分钟。

RTF 越低，意味着 TTS 系统生成语音的速度越快。实时因子低的 TTS 系统在需要实时响应的应用场景（如语音助手）中尤为关键。

## 附属链接

- [Sherpa-Onnx合成在线验证](https://huggingface.co/spaces/k2-fsa/text-to-speech)
